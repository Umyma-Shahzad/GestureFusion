# âœ‹ GestureFusion â€” A New Era of Gesture-Driven User Interfaces

**GestureFusion** is an interactive, real-time computer vision web application powered by Flask and OpenCV. GestureFusion allows users to explore multiple computer vision features from hand tracking to facial landmarking and gesture-based drawing all from an intuitive browser based interface.

ğŸŒŸ Built as a final project for the **Computer Vision** course, GestureFusion is designed to **demonstrate real-time gesture recognition**, **dynamic image filtering**, and **intuitive visualizations** â€” combining the power of AI, OpenCV, and frontend development.

---
## ğŸš€ Features

- ğŸ–Œï¸ **Air Drawing Canvas** â€“ Draw in the air using hand gestures
- ğŸŒŠ **Optical Flow Detection** â€“ Visualize motion between video frames
- ğŸ­ **Real-Time Filters** â€“ Apply fun and dynamic filters to your face
- ğŸ‘€ **Face and Eye Detection** â€“ Detect and track facial features
- ğŸ”Š **Volume Control** â€“ Adjust system volume using hand gestures
- ğŸ–±ï¸ **Virtual Mouse** â€“ Control mouse pointer through gesture input

ğŸ–¼ï¸ All features run **in-browser**, using your webcam â€” no uploads required!

---

## ğŸ“· Preview

> Frontend UI of GestureFusion with interactive gesture modules:

<img width="944" height="421" alt="image" src="https://github.com/user-attachments/assets/4d603443-87cd-47bc-aa60-41ade7585042" />

---

## ğŸ› ï¸ Tech Stack

| Backend | Frontend | CV/AI |
|--------|----------|--------|
| Flask (Python) | HTML5, CSS3, JavaScript | OpenCV, MediaPipe |

---

## âš™ï¸ Installation

1. **Clone the repo**:
   ```bash
   git clone https://github.com/Umyma-Shahzad/GestureFusion.git
   cd GestureFusion
   
2. **Install Dependencies:**
```bash
  pip install -r requirements.txt
```

3. **Run Application:**

```bash
  python app.py
```
4. **Open your browser and navigate to:**

     http://127.0.0.1:5000
  
---
## ğŸ“ **Project Structure**

GestureFusion/

â”œâ”€â”€ app.py

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ templates/

â”‚   â””â”€â”€ index.html

â”œâ”€â”€ static/

â”‚   â””â”€â”€ style.css

â”œâ”€â”€ AirDrawingCanvas.py

â”œâ”€â”€ Filters.py

â”œâ”€â”€ HandTrackingModule.py

â”œâ”€â”€ face_detection.py

â”œâ”€â”€ LucasKanadeMotionDetection.py

â”œâ”€â”€ volume_control.py

â”œâ”€â”€ mouse_control.py

â””â”€â”€ saved_drawings/

---

## ğŸ§  **Concepts Used**

  - Computer Vision

  - Optical Flow & Motion Tracking

  - Facial Landmark Detection

  - Gesture Recognition

  - Real-time Video Processing

  - Flask Web Integration

---
## ğŸ¤ Contributing
Contributions are welcome! Open an issue or pull request for any improvements, bug fixes, or new features.

---

## ğŸ“¬ **Contact**

Email: umymashahzad02@gmail.com

LinkedIn: https://www.linkedin.com/in/umyma-shahzad

---
## ğŸ™ Acknowledgments

- Mediapipe by Google for fast and accurate hand tracking

- Streamlit for making ML app deployment easy and beautiful
---

## ğŸ·ï¸ **Keywords**

â€¢ computer vision â€¢ gesture control â€¢ opencv â€¢ face detection â€¢ air drawing â€¢ real-time filters â€¢ virtual mouse â€¢ volume control â€¢ flask app â€¢ human-computer interaction â€¢computer vision project

---

## **â­ Don't forget to star the repo if you like it!**

